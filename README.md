# 矿大论坛 —— 集GPT与论坛于一体的一站式问答系统

---

### 1. **技术栈选择**

#### **后端框架：**

- **Spring Boot**：用于构建RESTful API，模块化强，便于扩展。
- **Spring Cloud**：微服务架构，适合高并发和分布式系统。可拆分成独立服务：用户服务、帖子服务、评论服务等。
- **Spring Security + OAuth2.0**：用于用户认证与授权，支持单点登录和第三方登录（如微信、GitHub）。
- **MyBatis-Plus**：提供了ORM功能，简化数据库操作，并且高效。
- **Nacos**：配置管理与服务注册发现。
- **Sentinel**：流量控制与熔断保护。
- **Seata**：分布式事务管理。

#### **数据库：**

- **MySQL**（或**PostgreSQL**）：关系型数据库，存储核心数据，如用户、帖子、评论等。
    - 可考虑使用**读写分离**和**分库分表**方案来提升数据库读写性能。
- **Redis**：用于缓存热数据，处理高并发下的快速响应。可缓存GPT回答、帖子内容、热点问题等。
- **Elasticsearch**：用于实现全文检索功能，方便用户快速搜索帖子、问题和答案。
- **MongoDB**：用于存储动态内容（如帖子的详细内容、评论数据等），特别是用户的操作日志、实时交互数据等场景，MongoDB的文档型存储方式支持结构化与非结构化数据的灵活存储，并且能够水平扩展。

#### **消息队列：**

- **Kafka**（或**RabbitMQ**）：用于处理系统的异步任务，如发布消息通知、异步保存GPT回答、点赞计数、帖子更新等。Kafka具备强大的吞吐能力，适合高并发场景。

#### **大规模任务处理：**

- **Spring Batch**：用于定时任务，如定时清理无用数据、重新计算帖子热度等。
- **Elastic Job**：分布式任务调度器，支持横向扩展。

#### **GPT集成：**

- **RAG（Retrieval-Augmented Generation）**：通过检索相关文档来增强GPT的回答能力，避免GPT单纯依赖生成式模型的局限性。
- **LangChain**：用于构建问答流程管理链，负责管理用户问题与GPT回答的处理过程，包括处理未回答问题的逻辑。

#### **API网关：**

- **Spring Cloud Gateway**：管理微服务的API请求，支持限流、熔断、负载均衡等，保证高并发下的稳定性。

#### **监控与日志：**

- **Prometheus + Grafana**：用于实时监控系统性能、流量、错误率等。
- **ELK Stack（Elasticsearch + Logstash + Kibana）**：日志采集和分析，用于排查故障。
- **SkyWalking**：分布式系统的全链路监控与性能追踪。

### 2. **数据库设计**

#### **表设计：**

- **用户表（user）**：存储用户的基本信息，如用户ID、用户名、邮箱、密码（加密）等。
- **帖子表（post）**：存储每个帖子的信息，如帖子ID、标题、内容、发布者、发布时间等。
- **评论表（comment）**：存储用户对帖子的评论信息，包括评论ID、内容、评论者、评论时间等。
- **点赞表（like）**：用于记录用户点赞的帖子或评论。
- **问题表（question）**：如果GPT未能回答问题，将问题保存至问题表中，关联用户和问题内容。
- **回答表（answer）**：存储用户对问题的回答，可以关联GPT的回答或其他用户的回答。
- **消息表（message）**：存储消息通知，用于异步通知用户相关的帖子、问题更新等。

#### **索引与分表：**

- **索引**：为`用户ID`、`帖子ID`、`发布时间`等常用字段建立索引，提升查询速度。
- **分表**：根据流量可将`帖子表`、`评论表`按日期、板块或用户ID进行分表。

#### **优化策略：**

- **读写分离**：将读操作转移到从库，写操作保留在主库，提升读性能。
- **分布式数据库**：可使用Sharding-JDBC进行分库分表，根据用户ID或帖子ID水平拆分数据。

### 3. **高并发处理**

- **缓存热点数据**：使用Redis缓存热门帖子、热点问题，避免频繁查询数据库。为不同的数据设定合理的过期时间，并采用LRU淘汰策略处理热点数据的失效和更新。
- **限流与熔断**：使用Sentinel对高频操作（如点赞、评论）进行限流，防止流量暴增时服务崩溃。
- **异步处理**：对于耗时的任务，如GPT回答、通知生成等，使用Kafka异步处理，设置多个分区提高消息处理的并发度。
- **CDN加速**：帖子中的图片、视频等静态资源可以通过CDN加速，提高用户访问速度。
- **数据库读写分离**：将读请求分发到从库，写请求保持在主库，减轻主库压力。

### 4. **GPT未回答时的处理流程**

1. **用户提问**：用户提问，首先调用GPT接口获取答案。如果响应时间过长（例如超过5秒），系统将进入备用方案流程。
2. **GPT回答失败**：若GPT无法回答（无结果或超时），将问题保存至数据库的**问题表**。考虑为问题生成一个缓存标识，避免多次重复查询相同问题。
3. **发布帖子**：系统自动在相关板块中发布此问题，同时生成新的帖子，邀请其他用户回答，系统会设置回答的优先级。
4. **问题更新**：一旦有用户或GPT完成回答，更新帖子内容并通知提问者，同时将该问题的缓存状态标记为已解决。

### 5. **运行指南**

1. 克隆项目：
   ```bash
   git clone https://github.com/wtmxxx/cumt-forum.git
   ```
2. 配置Nacos、Sentinel、Seata、MySQL、Redis等依赖的环境变量和配置文件。
3. 启动服务：
   ```bash
   ./mvnw spring-boot:run
   ```

### 6. **贡献指南**

欢迎对本项目提出问题、建议或者贡献代码，贡献流程如下：

1. Fork 项目
2. 创建新分支 (git checkout -b feature/your-feature)
3. 提交修改 (git commit -m 'Add some feature')
4. 推送到分支 (git push origin feature/your-feature)
5. 提交Pull Request

### 7. **项目展望**

- 实现更加智能的问答推荐系统，基于用户行为和GPT对话结果为用户推送相关的讨论内容。
- 支持更多类型的社交互动功能，如用户之间的私信、实时讨论等。
- 深化RAG与LangChain的集成，实现更加高效的多文档检索与问答功能。